# reagent environment configuration
#
# Copy this file to .env and fill in your values:
#   cp .env.example .env
#
# Model names use litellm's provider-prefix format.
# litellm reads API keys from env vars automatically.

# --- Anthropic ---
# ANTHROPIC_API_KEY=sk-ant-api03-your-key-here
# REAGENT_MODEL=anthropic/claude-sonnet-4-5-20250929
# REAGENT_FAST_MODEL=anthropic/claude-haiku-4-5-20251001
# REAGENT_CONTEXT_WINDOW=200000

# --- Gemini ---
# GEMINI_API_KEY=your-gemini-key-here
# REAGENT_MODEL=gemini/gemini-3-flash-preview
# REAGENT_FAST_MODEL=gemini/gemini-2.5-flash-preview
# REAGENT_CONTEXT_WINDOW=1000000

# --- OpenAI ---
# OPENAI_API_KEY=sk-your-key-here
# REAGENT_MODEL=openai/gpt-4o
# REAGENT_FAST_MODEL=openai/gpt-4o-mini
# REAGENT_CONTEXT_WINDOW=128000

# --- Reasoning Effort ---
# Set to enable thinking/reasoning tokens: "low", "medium", or "high".
# Supported on Anthropic (extended thinking), DeepSeek, Gemini, etc.
# When enabled, the model's internal reasoning is displayed in the UI.
# REAGENT_REASONING_EFFORT=low
# REAGENT_FAST_REASONING_EFFORT=low
